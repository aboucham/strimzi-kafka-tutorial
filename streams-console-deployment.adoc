= Deploying Your Streams Console: A Step-by-Step Guide

:toc: left
:toclevels: 3
:sectnums:

This guide details the step-by-step deployment of the Streams Console for Apache Kafka, including prerequisites, cluster installation, and OpenID Connect (OIDC) integration via KeyCloak, concluding with specific troubleshooting solutions.

== Environment Setup

 - Streams for Apache Kafka: 3.0.1-2 (Red Hat)
 - Streams for Apache Kafka Console: 3.0.1-3 (Red Hat)

=== Install Streams Operators

First, install the necessary Red Hat Operators for Streams for Apache Kafka (`amq-streams`) and the Streams Console (`amq-streams-console`) into the `openshift-operators`. namespace.

[source, bash]
----
oc apply -f - <<EOF
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  labels:
    operators.coreos.com/amq-streams.openshift-operators: ""
  name: amq-streams
  namespace: openshift-operators
spec:
  channel: stable
  installPlanApproval: Automatic
  name: amq-streams
  source: redhat-operators
  sourceNamespace: openshift-marketplace
  startingCSV: amqstreams.v3.0.0-13
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  labels:
    operators.coreos.com/amq-streams-console.openshift-operators: ""
  name: amq-streams-console
  namespace: openshift-operators
spec:
  channel: alpha
  installPlanApproval: Automatic
  name: amq-streams-console
  source: redhat-operators
  sourceNamespace: openshift-marketplace
  startingCSV: amq-streams-console.v3.0.0-10
EOF
----

*NOTE:* Wait for both subscriptions to reach Succeeded state before proceeding.

=== Install Kafka Cluster

We will deploy a Kafka cluster named `kafka-cluster` using the `Kraft` (Kafka Raft) mode. Ensure you are in the target namespace (e.g., `strimzi`).

[source, bash]
----
oc new-project strimzi
oc project strimzi
oc apply -f https://raw.githubusercontent.com/aboucham/strimzi-kafka-tutorial/refs/heads/main/kafka/full-Kafka-cluster-kraft.yaml
----

== Deploy Streams Console (Non-OIDC Examples)

=== Console with plain Listener and Explicit KafkaUser

This configuration uses a `Plain` listener and explicitly references a `KafkaUser` resource for connection.

[source, bash]
----
oc project strimzi

export KAFKA_CR_NAME="kafka-cluster"
export UI_CONSOLE_URL="my-console-ui.apps.abouchama-ai.emea.aws.cee.support"
export NAMESPACE="strimzi"
export KAFKA_LISTENER_NAME="plain"
# Name of the `KafkaUser` resource used to connect to Kafka
# This is optional if properties are used to configure the user
export KAFKA_CONSOLE_USER="console-kafka-user"
----

[source, bash]
----
cat <<'EOF' | envsubst | oc apply -f -
apiVersion: console.streamshub.github.com/v1alpha1
kind: Console
metadata:
  name: my-console
spec:
  hostname: $UI_CONSOLE_URL
  kafkaClusters:
    - name: $KAFKA_CR_NAME
      namespace: $NAMESPACE
      listener: $KAFKA_LISTENER_NAME
      credentials:
        kafkaUser:
          name: $KAFKA_CONSOLE_USER
EOF
----

=== Console with `plain` Listener (`Anonymous/Prompt Auth`)

This configuration omits the credentials section, which may prompt for credentials in the UI or rely on anonymous access (depending on Kafka cluster setup).

[source, bash]
----
cat <<'EOF' | envsubst | oc apply -f -
apiVersion: console.streamshub.github.com/v1alpha1
kind: Console
metadata:
  name: my-console
spec:
  hostname: $UI_CONSOLE_URL
  kafkaClusters:
    - name: $KAFKA_CR_NAME
      namespace: $NAMESPACE
      listener: $KAFKA_LISTENER_NAME
EOF
----

=== Console with `tls` Listener (`Anonymous/Prompt Auth`)

This configuration uses a `tls` listener. Ensure the Kafka cluster is configured for TLS.

[source, bash]
----
export KAFKA_LISTENER_NAME="tls"
----

[source, bash]
----
cat <<'EOF' | envsubst | oc apply -f -
apiVersion: console.streamshub.github.com/v1alpha1
kind: Console
metadata:
  name: my-console
spec:
  hostname: $UI_CONSOLE_URL
  kafkaClusters:
    - name: $KAFKA_CR_NAME
      namespace: $NAMESPACE
      listener: $KAFKA_LISTENER_NAME
EOF
----

== Deploy Streams Console with OIDC (KeyCloak)

This section covers setting up *KeyCloak* as an *OpenID Connect (OIDC)* provider and configuring the Streams Console to use it for authentication.

=== Deploy KeyCloak 26

Create a new project and deploy the KeyCloak Operator.

[source, bash]
----
oc new-project keycloak
oc project keycloak
----

Deploy KeyCloak Subscription:

[source, bash]
----
oc apply -f - <<EOF
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  labels:
    operators.coreos.com/rhbk-operator.keycloak: ""
  name: rhbk-operator
  namespace: keycloak
spec:
  channel: stable-v26.2
  installPlanApproval: Automatic
  name: rhbk-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
  startingCSV: rhbk-operator.v26.2.9-opr.1
EOF
----

Deploy Keycloak 26 Instance:

[source, bash]
----
oc apply -f https://raw.githubusercontent.com/aboucham/strimzi-kafka-tutorial/refs/heads/main/keycloak/keycloak-install.yaml
----

Retrieve the initial `admin` credentials:

[source, bash]
----
kubectl get secret -n keycloak example-kc-initial-admin -o jsonpath='{.data.username}' | base64 --decode
kubectl get secret -n keycloak example-kc-initial-admin -o jsonpath='{.data.password}' | base64 --decode
----

=== KeyCloak Configuration Steps

1- *Create Realm*: Create a new realm called `console-streams`.

2- *Create Client*:
   - Create a client ID: `console-streams-ui`.
   - Enable *Client authentication* to make the *Credentials* menu appear.
   - Copy the *Client Secret* (Example: `gcGZadb9sZGTGmXazW1HHkJEcMQ8eUje`).

3- *Create OIDC Secret*: Create an OpenShift secret for the Client Secret in the strimzi namespace.

[source, bash]
----
   oc create secret generic my-oidc-secret \
     --from-literal=client-secret=gcGZadb9sZGTGmXazW1HHkJEcMQ8eUje
----

4- *Create Groups & Roles*:
   - Create two *Groups*: `kafka-admins` and `kafka-devs`.
   - Create two *Realm Roles*: `administrators` and `developers`.

5- *Create Users*: Create two *Users*: `admin` and `dev`. Assign them to the respective `groups` and `roles`.

=== Deploy Streams Console with OIDC

Set OIDC-specific environment variables and deploy the console.

[source, bash]
----
oc project strimzi

export CONSOLE_CR_NAME="example"
export KAFKA_CR_NAME="kafka-cluster"
export UI_CONSOLE_URL="example-console.apps.abouchama-ai.emea.aws.cee.support"
export NAMESPACE="strimzi"
export KAFKA_LISTENER_NAME="plain"
# Name of the `KafkaUser` resource used to connect to Kafka
# This is optional if properties are used to configure the user
export KAFKA_CONSOLE_USER="console-kafka-user"
export OIDC_Discovery_URL=https://keycloak-host.apps.abouchama-ai.emea.aws.cee.support/realms/console-streams  
export CLIENT_ID=console-streams-ui
export ADMIN_GROUP=kafka-admins
export DEV_GROUP=kafka-devs
export ADMIN_ROLE=administrators
export DEV_ROLE=developers
----

*NOTE*: Replace `KeyCloak host` with your actual `KeyCloak route` and the same for `UI_CONSOLE_URL`.

[source, bash]
----
curl -sL https://raw.githubusercontent.com/aboucham/strimzi-kafka-tutorial/refs/heads/main/kafka/streams-console-oidc.yaml | \
envsubst | \
oc apply -f -
----

== Troubleshooting Specific Issues

Here are solutions for common issues encountered during the `OIDC` `Streams Console` deployment.

=== Error: 'self-signed certificate'

This error typically occurs when the Streams Console tries to communicate with KeyCloak (e.g., during the sign-in flow) and doesn't trust the Certificate Authority (CA) that issued the KeyCloak server's certificate.

**Log Message:**
[source, json,indent=0]
----
[next-auth][error][SIGNIN_OAUTH_ERROR]  
https://next-auth.js.org/errors#signin_oauth_error self-signed certificate {  
error: {  
message: 'self-signed certificate',  
stack: 'Error: self-signed certificate\n' +  
' at TLSSocket.onConnectSecure (node:\_tls_wrap:1679:34)\n' +  
// ... stack trace ...
name: 'Error'  
},  
providerId: 'oidc',  
message: 'self-signed certificate'  
}
----

**Solution: Inject KeyCloak's CA into the Console Trust Store**

1.  Extract the KeyCloak service certificate (assuming it's stored in a secret named `example-tls-secret` in the `keycloak` namespace).

[source, bash,indent=0]
----
rm tls.crt
oc extract secret/example-tls-secret -n keycloak --confirm
----

2.  Create a secret in the `strimzi` namespace containing the certificate.

[source, bash,indent=0]
----
oc create secret generic oidc-ca-certificates --from-file=tls.crt
----

3.  Update your `Console` custom resource (CR) to include a `trustStore` reference to this secret.

[source, yaml,indent=0]
----
  trustStore:
    content:
      valueFrom:
        secretKeyRef:
          key: tls.crt
          name: oidc-ca-certificates
----

=== Error: 'Invalid scopes: openid email profile groups'

This error indicates that the *Scopes* requested by the Streams Console client are *not defined or enabled* on the KeyCloak client configuration.

Log shows:

[source, json,indent=0]
----
\[next-auth\]\[error\]\[OAUTH_CALLBACK_HANDLER_ERROR\]  
https://next-auth.js.org/errors#oauth_callback_handler_error invalid_scope {  
error: {  
message: 'invalid_scope',  
stack: 'Error: invalid_scope\\n' +  
' at c (/app/.next/server/chunks/3123.js:1:120823)\\n' +  
' at Object.l (/app/.next/server/chunks/3123.js:25:799)\\n' +  
' at m (/app/.next/server/chunks/3123.js:1:104470)\\n' +  
' at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\\n' +  
' at async o (/app/.next/server/chunks/3123.js:25:19768)\\n' +  
' at async e.length.t (/app/.next/server/chunks/3123.js:25:21258)\\n' +  
' at async /app/node_modules/next/dist/compiled/next-server/app-route.runtime.prod.js:6:38411\\n' +  
' at async e_.execute (/app/node_modules/next/dist/compiled/next-server/app-route.runtime.prod.js:6:27880)\\n' +  
' at async e_.handle (/app/node_modules/next/dist/compiled/next-server/app-route.runtime.prod.js:6:39943)\\n' +  
' at async doRender (/app/node_modules/next/dist/server/base-server.js:1366:42)',  
name: 'Error'  
},  
error_description: 'Invalid scopes: openid email profile groups',  
providerId: 'oidc',  
message: 'invalid_scope'  
}
----

*Solution*: *Add Requested Scopes in KeyCloak*

=== Error: 'Invalid scopes: openid email profile groups'

This error indicates that the **Scopes** requested by the Streams Console client are **not defined or enabled** on the KeyCloak client configuration.

**Log Message:**
[source, json,indent=0]
----
[next-auth][error][OAUTH_CALLBACK_HANDLER_ERROR]  
https://next-auth.js.org/errors#oauth_callback_handler_error invalid_scope {  
// ... stack trace ...
error_description: 'Invalid scopes: openid email profile groups',  
// ...
----

**Solution: Add Requested Scopes in KeyCloak**

1.  Navigate to your **KeyCloak Admin Console**.
2.  Go to **Client Scopes**.
3.  Create a new **Client Scope** that includes all the required scopes: `"openid email profile groups"`.
4.  Navigate to **Clients** and select `console-streams-ui`.
5.  In the client's settings, assign the newly created scope (or the individual scopes: `openid`, `email`, `profile`, and `groups`) to the client. *Ensure they are listed under **Assigned Client Scopes**.*

=== Error: "Not Authorized" / Missing Groups Claim

This issue is often seen when the user successfully authenticates via OIDC, but the Streams Console cannot authorize them because the required **group membership information is missing** from the JWT Access Token.

**Log Message:**
* You may see an explicit `403 Not Authorized` in the UI, or a `JWT_SESSION_ERROR` in the logs attempting to refresh a token or fetch user info.
* The log may show a message like: `TypeError: fetch failed` or indicate a problem retrieving session data, often masking the underlying authorization failure due to missing claims.

[source, json,indent=0]
----
[next-auth][error][JWT_SESSION_ERROR]  
https://next-auth.js.org/errors#jwt_session_error fetch failed {  
message: 'fetch failed',  
// ... stack trace ...
name: 'TypeError'  
}
----

**Solution: Configure Group Membership Mapper in KeyCloak**

KeyCloak does **not** include user groups in the JWT by default; you must configure a **Mapper** to explicitly add them.

1.  Navigate to the **KeyCloak Admin Console**.
2.  Go to **Client Scopes**.
3.  Select the **Client Scope** that your client (`console-streams-ui`) is using.
4.  Go to the **Mappers** tab.
5.  Click **Add Mapper** → **By Configuration** → **Group Membership**.
6.  Configure the mapper:
    * **Name:** `groups` (or `kafka-groups-mapper`)
    * **Mapper Type:** `Group Membership`
    * **Token Claim Name:** `groups` (This is the critical claim name the console looks for).
    * **Full group path:** **OFF** (This keeps the claim simple, e.g., `["kafka-admins"]`).
    * **Add to access token:** **ON** (Crucial for authorization).
7.  Click **Save**.
