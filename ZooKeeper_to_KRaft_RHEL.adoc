= Streams for Apache Kafka 2.9: ZooKeeper to KRaft Migration Guide
:toc:
:toc-title: Table of Contents
:icons: font
:source-highlighter: highlight.js

== ℹ️ Prerequisites and Cluster Information

This guide covers the migration of a minimal Kafka 3.9 cluster (Streams for Apache Kafka 2.9) running with ZooKeeper to a KRaft-based quorum in a single-host testing environment. All steps assume execution from the Kafka installation directory (e.g., `~/Downloads/kafka_2.13-3.9.1.redhat-00006-2`).

.Cluster Details
|===
| Element | Value / Role
| **Real Cluster ID** (Obtained from ZK) | `SY9T31EKSS6XeNO_Jio6yQ`
| **ZK Broker ID** | `broker.id=0`
| **KRaft Controllers (Simulated Quorum)** | `node.id=100`, `101`, `102`
| **KRaft Controller Ports** | `9090`, `9091`, `9094`
| **Broker Client Port** | `9092`
|===

// ----------------------------------------------------------------------------------------------------------------------
---

== Chapter 1: Starting the ZooKeeper/Kafka Server

This sequence ensures Kafka starts correctly, verifying ZK dependencies are met before starting the Kafka Broker.

=== 1.1. Start ZooKeeper

The ZooKeeper server must be running to provide metadata services before Kafka can launch.

[source, bash]
----
./bin/zookeeper-server-start.sh -daemon ./config/zookeeper.properties
----

**Verification (Expected Output):**
[source, bash]
----
jcmd | grep zookeeper
37288 org.apache.zookeeper.server.quorum.QuorumPeerMain ./config/zookeeper.properties
----

=== 1.2. Start the Kafka Broker

Start the Kafka Broker, which registers itself with the running ZooKeeper instance.

[source, bash]
----
./bin/kafka-server-start.sh -daemon ./config/server.properties
----

**Verification (Expected Output):**
[source, bash]
----
jcmd | grep kafka
38247 kafka.Kafka ./config/server.properties
----

=== 1.3. Test Messaging Functionality

Verify that the broker is fully operational by sending and consuming messages.

[source, bash]
----
echo "Test message using console-producer and console-consumer" | ./bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic my-test-topic
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-test-topic --from-beginning --max-messages 1
----

// ----------------------------------------------------------------------------------------------------------------------
---

== Chapter 2: ZooKeeper to KRaft Migration (Dual-Write Phase)

This phase enables the *Dual-Write* mode, where ZooKeeper and the new KRaft quorum manage metadata simultaneously, preparing for the final transition.

The migration from ZooKeeper to KRaft (Kafka Raft metadata) mode is a multi-step process that allows a cluster to transition without downtime. Kafka version 3.9 is the final version to support ZooKeeper.

==== Prerequisites for Migration
- Your Kafka cluster must be running Streams for Apache Kafka 2.7 or newer with Kafka 3.7.0 or newer.
- You are logged in to RHEL as the kafka user.
- The original cluster uses dedicated controller nodes (migration is not supported for nodes in combined broker/controller mode during migration).
- You have the Cluster ID retrieved from the installation step.
- Logging should be enabled for troubleshooting (e.g., set `log4j.rootLogger=DEBUG` and `log4j.logger.org.apache.kafka.metadata.migration=TRACE`).

=== 1 - Retrieve Cluster ID

Get the cluster ID using the `zookeeper-shell` tool:

[source, bash]
----
./bin/zookeeper-shell.sh localhost:2181 get /cluster/id
----

**Verification (Output) :**

[source, bash]
----
Connecting to localhost:2181

WATCHER::

WatchedEvent state:SyncConnected type:None path:null
{"version":"1","id":"SY9T31EKSS6XeNO_Jio6yQ"}
----

=== 2 - Configure KRaft Controllers (Dedicated Role)

The controllers must be configured with the dedicated role (`process.roles=controller`) and unique ports to avoid conflicts with the existing Broker on port 9092.

.Configuration for `controller-100.properties` (Adapt for 101/9091 and 102/9094)
[source, properties]
----
process.roles=controller
node.id=100
# Must be unique for each controller
log.dirs=/tmp/kafka-metadata-100 

# Listener is for KRaft Quorum communication only (no client API)
listeners=CONTROLLER://0.0.0.0:9090
controller.listener.names=CONTROLLER
listener.security.protocol.map=CONTROLLER:PLAINTEXT 

# List of all controllers in the quorum
controller.quorum.bootstrap.servers=localhost:9090,localhost:9091,localhost:9094

# Enable Migration and ZK Connection
zookeeper.metadata.migration.enable=true
zookeeper.connect=localhost:2181 
----

=== 3 - Format and Start KRaft Controllers

Format Log Directories for Controllers For each controller node, format the storage using the `retrieved cluster ID`:

1.  **Format Log Directories (Using the Actual Cluster ID):**

[source, bash]
----
./bin/kafka-storage.sh format --cluster-id SY9T31EKSS6XeNO_Jio6yQ --standalone --config ./config/kraft/controller-100.properties
./bin/kafka-storage.sh format --cluster-id SY9T31EKSS6XeNO_Jio6yQ --standalone --config ./config/kraft/controller-101.properties
./bin/kafka-storage.sh format --cluster-id SY9T31EKSS6XeNO_Jio6yQ --standalone --config ./config/kraft/controller-102.properties
----

**Verification (Output) :** `Formatting dynamic metadata voter directory ... with metadata.version 3.9-IV0.`

2.  **Start the KRaft Controllers:**
    (Ensure ZooKeeper is still running before this step.)

[source, bash]
----
./bin/kafka-server-start.sh -daemon ./config/kraft/controller-100.properties
./bin/kafka-server-start.sh -daemon ./config/kraft/controller-101.properties
./bin/kafka-server-start.sh -daemon ./config/kraft/controller-102.properties
----

    **Verification (jcmd):** Confirms all three controller processes are running.

[source, bash]
----
jcmd | grep kafka
27330 org.apache.zookeeper.server.quorum.QuorumPeerMain /tmp/kafka_base/kafka/config/zookeeper.properties
6340 kafka.Kafka ./config/kraft/controller-100.properties
27946 kafka.Kafka /tmp/kafka_base/kafka/config/server.properties
6924 kafka.Kafka ./config/kraft/controller-101.properties
7503 kafka.Kafka ./config/kraft/controller-102.properties
----

=== 4 - Enable Dual-Write on the Existing Broker

Enable Migration on Brokers and Rolling Restart (Phase 2) On each existing Kafka broker (one by one), enable migration by updating its configuration (`./config/server.properties`):

- Add zookeeper.metadata.migration.enable=true.
- Add the controller connection details (e.g., listeners, controller.listener.names, controller.quorum.bootstrap.servers).
- Set inter.broker.protocol.version to a supported version (e.g., 3.9).
- Perform a graceful restart of the broker.

1.  **Update `server.properties`:** Add/modify the following properties in your main broker config:

[source, properties]
----
# Add CONTROLLER listener for communication with KRaft quorum (using a free port, e.g., 9093)
listeners=PLAINTEXT://:9092,CONTROLLER://:9093
listener.security.protocol.map=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT

# Activate Dual-Write Mode
zookeeper.metadata.migration.enable=true
inter.broker.protocol.version=3.9

# Configure the KRaft quorum connection for the broker
controller.listener.names=CONTROLLER
controller.quorum.bootstrap.servers=localhost:9090,localhost:9091,localhost:9094
----

2.  **Rolling Restart of the Broker (Activates Dual-Write):**

[source, bash]
----
./bin/kafka-server-stop.sh
./bin/kafka-server-start.sh -daemon ./config/server.properties
----

=== 2.4. Final Migration Validation (Dual-Write Complete)

Monitor the active KRaft controller's log (e.g., controller 100) for the final confirmation message.

[source, bash]
----
grep "Completing migration of ZooKeeper metadata to KRaft" ./logs/controller.log
[2025-11-18 10:59:07,198] INFO [QuorumController id=100] Completing migration of ZooKeeper metadata to KRaft. (org.apache.kafka.controller.QuorumController)
----
Once this log entry appears, the cluster is operating stably in the Dual-Write mode.

You can check also Zookeeper registry to get the information about the Kraft Leader / 
[source, bash]
----
/bin/zookeeper-shell.sh localhost:2181 get /migration

Connecting to localhost:2181

WATCHER::
WatchedEvent state:SyncConnected type:None path:null
{"version":0,"kraft_metadata_offset":1296,"kraft_controller_id":100,"kraft_metadata_epoch":3,"kraft_controller_epoch":3}
----

You can check also for the following log entries in the Kafka broker's `server.log` that confirm successful registration to both ZooKeeper and the KRaft quorum after enabling the migration configuration (Dual-Write mode):

Zookeeper:

[source, bash]
----
----

Kraft:

[source, bash]
----
----


// ----------------------------------------------------------------------------------------------------------------------
---

== Chapter 3: Finalize Migration

1. **Wait for Migration Completion** Monitor the logs on the active controller for an `INFO` log indicating: `Completed migration of metadata from ZooKeeper to KRaft`.

2. **Switch Brokers to KRaft Mode and Rolling Restart** On each broker (one by one), update the configuration and perform a graceful restart:

- Replace `broker.id` with `node.id` (**using the same ID**).
- Add `process.roles=broker`.
- Remove `inter.broker.protocol.version`.
- Remove `zookeeper.metadata.migration.enable`.
- Remove `zookeeper.connect`.
- Remove `control.plane.listener.name` (if present).
- If using ACLs, update the authorizer class name: `authorizer.class.name=org.apache.kafka.metadata.authorizer.StandardAuthorizer`
(from `kafka.security.authorizer.AclAuthorizer` for ZooKeeper-based brokers) .

- Perform a graceful restart.

Example of `server.properties`:

[source, properties]
----
############################# Server Basics #############################
# The id of the broker. This must be set to a unique integer for each broker.
#broker.id=0
node.id=0
process.roles=broker

num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600

log.dirs=/tmp/kafka-logs
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.retention.check.interval.ms=300000
group.initial.rebalance.delay.ms=0

listeners=PLAINTEXT://:9092
#listener.security.protocol.map=PLAINTEXT:PLAINTEXT
advertised.listeners=PLAINTEXT://localhost:9092

# Activate Dual-Write Mode
#zookeeper.metadata.migration.enable=true
#inter.broker.protocol.version=3.9

# Configure the KRaft quorum connection for the broker
controller.listener.names=CONTROLLER
controller.quorum.bootstrap.servers=localhost:9090,localhost:9091,localhost:9094
----

**verification:**

[source, bash]
----
 grep "Starting request manager" ./logs/server.log
[2025-11-18 16:19:30,222] INFO [RaftManager id=0] Starting request manager with bootstrap servers: [localhost:9090 (id: -2 rack: null), localhost:9091 (id: -3 rack: null), localhost:9094 (id: -4 rack: null)] (org.apache.kafka.raft.KafkaRaftClient)
----

[source, bash]
----
grep "Kafka Server started" ./logs/server.log
[2025-11-18 16:19:31,146] INFO [KafkaRaftServer nodeId=0] Kafka Server started (kafka.server.KafkaRaftServer)
----

3. **Switch Controllers out of Migration Mode** On each controller node (one by one), update the configuration and perform a restart:

- Remove `zookeeper.connect`.
- Remove `zookeeper.metadata.migration.enable`.
- Remove `inter.broker.listener.name`.
- Restart the controller.

Once completed, your Kafka cluster is fully operating in KRaft mode. You can now decommission the ZooKeeper nodes.

**Warning:** Once the migration is finalized (step 3 in Phase 3), **rollback to ZooKeeper is no longer possible**.

== Chapter 4: Stopping and Cleaning Up Services

### 4.1. Stop Services

1.  **Stop the Kafka Broker (Dual-Write):**

[source, bash]
----
./bin/kafka-server-stop.sh
----

2.  **Stop the KRaft Controllers:**
    (Use the PIDs listed by `jcmd | grep controller`)

[source, bash]
----
# Example: kill <PID_100> <PID_101> <PID_102>
kill 42577 43721 43151
----

3.  **Stop ZooKeeper:**

[source, bash]
----
./bin/zookeeper-server-stop.sh
----

### 4.2. Clean Data Directories

To completely reset the environment, delete the data directories (use caution with `rm -rf`).

[source, bash]
----
# 1. Remove Kafka Data (Topics)
rm -rf /tmp/kafka_base/*

# 2. Remove ZooKeeper Data (Logs/Snapshots)
rm -rf /tmp/zookeeper/*

# 3. Remove KRaft Metadata Logs
rm -rf /tmp/kafka-metadata-100 /tmp/kafka-metadata-101 /tmp/kafka-metadata-102
rm -rf /tmp/kafka-logs/* # If using /tmp/kafka-logs for non-KRaft data

# 4. remove logs
rm -rf ./logs
----
